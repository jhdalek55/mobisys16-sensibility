\section{Motivation}\label{sec-motivation}

%\textbf{Privacy and security risks.}
Due to recent privacy breaches and security break-ins to mobile systems, 
device security and personal privacy are genuinely at risk when a person 
uses a smartphone or tablet \cite{breach}. 
%Apps can post tweets to a 
%user's Twitter account without asking for permission~\cite{tweet}. 
A calculator app might send the user's location to an advertisement 
server~\cite{calc}. Sensor data from the accelerometer 
or gyroscope can be sufficient to infer the locations of touch-screen 
taps, and thus infer a user's password~\cite{cai2011touchlogger}.
Compromised apps can even let criminals break into an individual's 
bank account~\cite{starbucks}. 
%As a result, device owners 
%are aware that running apps on their smartphones can raise privacy 
%and security risks. 
A major reason for the prevelant privacy breaches is that on many mobile 
systems, such as Android, 
only a sub-set of sensors like GPS and bluetooth are considered risky, 
and their access is mediated~\cite{android-sec}. Other sensors 
such as accelerometer, gyroscope, etc., 
%are considered to be innocuous, 
require no permission to access. Furthermore, %research shows that 
device owners are often oblivious to the implications of granting access to
a particular type of sensor or resource~\cite{felt2012android}. It is 
therefore challenging to conduct research on end-user devices
in compliance with ethical standards~\cite{zevenbergen2013ethical}.

However, having access to data from the enormous number of smartphones 
in use today could be tremendously valuable to the research 
community. As these devices belong to ordinary people, conducting
research on these devices does not incur high maintenance costs. 
Accelerometers on end-user devices could detect vibrations within 
the frequency and intensity range of seismic waves, and assist 
distributed earthquake detection~\cite{faulkner2011next}. GPS, 
WiFi, and cellular triangulation can be employed in distributed 
networks of sensors for traffic monitoring and accident 
prevention~\cite{mohan2008nericell, thiagarajan2009vtrack}. 
For the research community, accessing this data depends on its 
ability to provide strong protection to device owners from privacy 
and security breaches. In this work, we try to address two issues. 

\textbf{Data access restrictions.}
%Despite these risks of using sensors, 
Studies have indicated that 
sensor data can be accessed without compromising device 
owners' privacy or sacrificing service functioning.
A recent research study shows that more than half of the 
surveyed individuals had no problem in supplying imprecise 
sensor data from their personal devices~\cite{fawaz2014location}. 
Most participants could accommodate some inevitable loss of application 
functionality, as long as their privacy was protected. Those surveyed
applications ranged from location-based search (e.g., Yelp), social 
network apps, to gaming and weather forcasting apps. 
Researchers thus have proposed 
substituting mocked~\cite{beresford2011mockdroid} or 
anonymized~\cite{zhou2011taming} data in place of real data. 
For example, in location-bases services such as maps, 
restaurant guides, and bus schedules, end users can still use the 
service even if a device only provides a discretized 
location~\cite{amini2011cache, krumm2007inference}. Therefore, 
though the accuracy of the data is reduced, 
the imprecise information is sufficient for a large class of services. 
%The US Federal Communications Commission requires 
%emergency rescue and 
%response teams to be able to estimate a 911 wireless emergency 
%caller's position with an accuracy of 125~m~\cite{gruteser2003anonymous, 
%reed1998overview}. \yanyan{too many examples?}

Based on these fact, restricting 
the amount of data accessible, such as reducing the precision or 
access frequency, will be a good privacy protection mechanism we can 
provide to end users. In this work, we coin the term \textit{data blurring}
as our privacy protection mechanism. This mechanism is used in 
conjunction with a researcher's IRB policies. 
%where each data access
%policy is codified as a blurring layer, and different policies are
%customized by loading individual blurring layers in order.

\textbf{IRB policies.}
%On the other hand, research institutions have also designed a 
%protocol based on the \textit{institutional review board (IRB)}, 
%to assess the ethics of a researcher's project, and review its methods. 
Another issue we sought to address with Sensibility Testbed is to 
relieve the individual researcher of the need to manually enforce 
the restrictions set by his or her institution's IRB.
IRB, also known as an independent ethics committee (IEC), ethical 
review board (ERB), or research ethics board (REB), is a committee 
that has been formally designated to approve, monitor, and review 
research involving human subjects~\cite{irb}. Although many current network 
testbeds require that researchers obtain IRB approval before conducting
an experiment on the testbed, these platforms do not provide a guarantee 
for IRB policy compliance. In the case of PhoneLab, 
%it requires experimenters to obtain IRB approval. However, 
it leaves it up to the experimenters to comply with their IRB policies in their 
experiments~\cite{nandugudi2013phonelab}. Similarly, 
Mobilyzer~\cite{nikravesh2015mobilyzer} provides a measurement
library that can be included in Android apps. 
%and requires explicit user consent. 
There is no guarantee that an 
experiment will be compliant with the researcher's IRB policies.
%promotes fully informed 
%consent and voluntary participation by prospective subjects. 

Sensibility Testbed takes any researcher's IRB policies, and codifies 
them to restrict sensor access on an end-user's device to 
an institution's set access levels. 
%IRB plays a central role in defining the policies
%appropriate for research at individual institutions. Experimenters
%first obtain an IRB approval at their institution. Then with these IRB
%policies, Sensibility Testbed, as an intermediate, codifies the data access 
%regulations and enforces them at the end-user mobile devices. 
This is achieved through restricting data access  via
a set of blurring layers. Each layer implements an IRB policy by substituting 
approximate data in place of explicit, raw sensor data to the experiment code. Different layers 
together can be customized to cater to various institution's 
policies and regulations. Our goal is to facilitate the enforcement of 
IRB policies on behalf of researchers, such that experiments 
do not collect more data than needed to provide their functionalities.
This will also relieve researchers from the tedious work of 
recruiting participants and enforcing IRB policies.

%In the domain of IRB, Alice and Bob are the participating subject, and 
%a researcher who conducts a research study on the subject, respectively.
%
%
%\textbf{Sensibility Testbed's default policies.}

\begin{table}
\scriptsize
\centering

\bgroup
\def\arraystretch{1.15}% % for table padding
\begin{tabular}{|l|c|c|c|}
\hline
\multirow{2}{*}{\bf Sensor} & 
\multicolumn{3}{c|}{\bf Default policy} \\\cline{2-4}
& {\bf LR} & {\bf MR} & {\bf HR} \\\hline

Battery (plug-in type, level, technology, etc.) & \tickmark &  & \\ \hline
Bluetooth (local name, scan mode, etc.) & & \tickmark & \\ \hline

\multirow{2}{5.5cm}{Cellular network (cell ID, area code, country code, 
operator name, etc.)} & & \multirow{2}{*}{\tickmark} & \\ 
& & & \\ \hline

Location (latitude, longitude, altitude, speed, etc.) & & \tickmark & \\ \hline
Settings (screen brightness, ringer volume, etc.) & & \tickmark & \\ \hline

\multirow{2}{5.5cm}{Motion sensors (accelerometer, 
gyroscope, magnetometer, orientation , etc.)} & & \multirow{2}{*}{\tickmark} & \\ 
& & & \\ \hline

\multirow{2}{5.5cm}{WiFi network (information about the 
currently active access point, and WiFi scan result)} & & \multirow{2}{*}{\tickmark} & \\ 
& & & \\ \hline 

%Start/stop activities & & & \xmark \\ \hline 
%Running applications & & & \xmark \\ \hline 
Camera (take pictures, record videos) & & & \xmark \\ \hline 
Intent (scan barcode, search, etc.) & & & \xmark \\ \hline 
Address book & & & \xmark \\ \hline 
Microphone (voice record) & & & \xmark \\ \hline 
SMS (send/receive messages, delete messages) & & & \xmark \\ \hline 

\end{tabular}
\egroup

\caption{\small Sensibility Testbed's default policies for sensors. LR/MR/HR
stands for low/moderate/high risk, respectively. Access is only allowed to sensors that have low to 
moderate risks (marked by \tickmark). Sensors that are highly risky are 
disabled by default (marked by \xmark).}
\label{tab:default}
%\vspace{-10pt}
\end{table}

\textbf{Sensibility Testbed's default policies.} %\label{sec-irb-policies}
Although Sensibility Testbed codifies IRB policies, 
a researcher cannot request complete access to all sensors 
even if his IRB approves such a policy. The Sensibility Testbed's
own IRB designates a set of default policies to access sensors in a
way that is low to moderate risk. 
%and for which access can be pre-approved with the
%researcher's local IRB. 
Only those sensors listed on our project 
wiki page~\cite{sensor-api} are accessible to a researcher. 
A summary of these sensors is listed in Table~\ref{tab:default}, 
where each sensor is categorized as low, moderate or high 
privacy risk.

The list of sensors that Sensibility Testbed provides are all of moderate 
to low privacy risks (marked by \tickmark), and the testbed further provides policy enforcement
(Section~\ref{sec-policy}) to protect all the sensor data. Sensors 
such as cameras and microphones that are deemed sensitive are not 
exposed to experiment code by default (marked by \xmark). Such 
classification is motivated by the Android system, where 
permissions are categorized into different protection levels~\cite{level}:
\textit{normal} permissions are automatically granted to the apps, 
\textit{dangerous} permissions are given based upon the 
user's consent, and so on. In our case, 
%we divide sensors into different risk levels, as shown 
%in Table~\ref{tab:default}. 
%Sensors with low to moderate risk are 
%allowed and protected by IRB policies. Sensors of high risk are 
%disabled by default. 
we divide sensors into different risk levels by the consequences and 
difficulties of a potential attack. If a microphone is controlled by 
a malicious party, it can be used to intelligently choose data of a 
higher value (e.g., credit card number, password) to record~\cite{zhang2015leave}. On the other 
hand, in order to infer a credit card number or password typed on a 
smartphone using motion sensors, the attack requires the installation of 
a sophisticated algorithm on the device that constantly learns about  
the patterns of data generated by accelerometer or gyroscope. In contrast,
using battery information alone is not sufficient to create a fingerprint 
for each device. Different information and mutiple occurrences need to
be pieced together to extract this data~\cite{battery-priv}. Therefore, 
compared to motion sensors, a microphone is considered a higher risk, 
and a battery is a significantly lower risk.

Although high-risk sensors are disabled, if such access  is critical to the 
study, access can be requested using a different IRB procedure. 
In this case, the research project has to go through the Sensibility 
Testbed's IRB, in addition to the researcher's IRB. 
\yanyan{if we think this is ok, then we provide specially
designed interface and policy?} \lois{following up on Yanyan's comment--If the Testbed's IRB says this expanded access is permissable, are the device owner's notified and can they opt out of this study? Otherwise, that would be a direct violation of the privacy protection you claim to give them}
%Depending on the experiment description provided by the 
%researcher, the fields marked with a (*) are the ones that will be blurred.
%
%
As a result, Sensibility Testbed does not
provide unfettered access to all sensors. 
%Access to sensors of
%higher risk, e.g., the policies that request restricted sensor data, 
%or at higher frequencies than our default policies, 
%needs to go through the Sensibility Testbed's IRB,
%in addition to the researcher's IRB. 
The default policies serve as a common denominator to all 
researchers' IRB policies. In most cases, we expect
that researchers need only go through their local IRB to get
the sensor access they need for their experiment. 
