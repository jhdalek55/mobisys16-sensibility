\section{Motivation}\label{sec-motivation}

\textbf{Privacy and security of mobile devices.}
Recent privacy breaches and security break-ins of mobile systems 
have resulted in higher concerns about using mobile devices like 
smartphones and tablets~\cite{breach}. Apps can post tweets to a 
user's Twitter account without asking for permission~\cite{tweet}. 
Compromised apps can even let criminals break into individual's 
bank account~\cite{starbucks}. As a result, many device owners 
are aware that running apps on their smartphones can raise privacy 
and security risks. 

However, data from the enormous number of smartphones, 
if used properly, can be of tremendous value to the research 
community, with little or no dedicated infrastructure and maintenance 
cost. For example, accelerometers on end-user devices can 
detect vibrations within the frequency and intensity range of 
seismic waves, and can assist distributed earthquake 
detection~\cite{faulkner2011next}. Cameras, GPS, WiFi, and 
cellular triangulation can be employed in distributed networks 
of sensors for traffic monitoring and accident 
prevention~\cite{mohan2008nericell, thiagarajan2009vtrack}. 
The challenge to providing data access to the research community
depends on strong protection against privacy and security breaches.

\textbf{Restricting accessible data.}
Despite the risks of using sensors, 
studies have indicated that we can access and use sensor data 
without compromising device owners' privacy or service functioning.
A recent research study has shown that more than half of the 
surveyed individuals had no problem in supplying imprecise 
sensor data from their personal devices to protect their 
privacy~\cite{fawaz2014location}. Researchers thus have proposed 
substituting mocked~\cite{beresford2011mockdroid}, anonymized 
or bogus~\cite{zhou2011taming} data in place of real data. Although
the accuracy of the data is reduced, experience shows
that the imprecise information is sufficient for a large class of 
services. For example, the US Federal Communications Commission requires 
that instead of the exact location, the emergency rescue and 
response teams are able to estimate the 911 wireless emergency 
caller's position with an accuracy of 125~m~\cite{gruteser2003anonymous, 
reed1998overview}. 

Based on these fact, restricting 
the amount of data accessible, such as reducing the precision or 
access frequency, can be a good privacy protection mechanism we can 
provide for end users. In this work, we coin the term \textit{data blurring}
as our privacy protection mechanism. This mechanism is used in 
conjunction with a researcher's IRB policies. 
%where each data access
%policy is codified as a blurring layer, and different policies are
%customized by loading individual blurring layers in order.

\textbf{Institutional review board (IRB).}
IRB, also known as an independent ethics committee (IEC), ethical 
review board (ERB), or research ethics board (REB), is a committee 
that has been formally designated to approve, monitor, and review 
research involving humans~\cite{irb}. The IRB protocol assesses 
the ethics of the research and its methods. However, the current network 
testbeds do not provide guarantee for IRB policy compliance.
In the case of PhoneLab, it requires experimenters to 
obtain IRB approval. However, it leaves it up to the experimenters 
to comply with their IRB policies in their 
experiments~\cite{nandugudi2013phonelab}. Similarly, 
Mobilyzer~\cite{nikravesh2015mobilyzer} provides a measurement
library that can be included in Android apps. 
%and requires explicit user consent. 
There is no guarantee that an 
experiment will be compliant with the researcher's IRB policies.
%promotes fully informed 
%consent and voluntary participation by prospective subjects. 

In Sensibility Testbed, IRB plays a central role in defining the policies
appropriate for research at individual institutions. Experimenters
first obtain an IRB approval at their institution. Then with these IRB
policies, Sensibility Testbed, as an intermediate, codifies the data access 
regulations and enforces them at the end-user 
mobile devices. This is achieved through restricting data access via
a set of blurring layers. Each layer implements an IRB policy by returning 
less precise sensor data to the experiment code. Different layers 
together can be customized to cater to various institution's 
policies and regulations.